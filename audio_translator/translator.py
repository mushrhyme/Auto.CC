import os
import asyncio
import threading
from datetime import datetime
from functools import partial

from config_manager import ConfigManager
from logger_manager import LoggerManager
from vad_detector import VADDetector
from audio_streamer import AudioStreamer
from audio_utils import save_wav
from clients import WhisperClient, GPTClient
from constants import RATE, CHUNK, CHANNELS
from signal_utils import get_audio_level

class Translator:
    def __init__(self):
        # ì„¤ì • ë¶ˆëŸ¬ì˜¤ê¸°
        self.config = ConfigManager()
        self.silence_threshold = self.config["silence_threshold"]
        self.silence_duration = self.config["silence_duration"]
        self.translation_mode = self.config["translation_mode"]
        self.preferred_device = self.config["preferred_device"]
        self.update_interval = self.config["update_interval"]

        # ë¡œê±°
        self.logger = LoggerManager.setup_logger()
        api_key = os.environ.get("OPENAI_API_KEY")
        if not api_key:
            self.logger.error("OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            raise RuntimeError("OPENAI_API_KEY not set")

        # í´ë¼ì´ì–¸íŠ¸
        self.whisper = WhisperClient(api_key)
        self.gpt = GPTClient(api_key)

        # ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¬ë° ë° VAD
        self.streamer = AudioStreamer(device_index=self.preferred_device)
        self.vad = VADDetector(
            threshold=self.silence_threshold,
            duration=self.silence_duration,
            sample_rate=RATE,
            chunk_size=CHUNK
        )
        # self._calibrate_ambient()
        # ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¬ë° ë° VAD (ìº˜ë¦¬ë¸Œë ˆì´ì…˜ì€ start()ì—ì„œ)
        self.streamer = AudioStreamer(device_index=self.preferred_device)
        self.vad = VADDetector(
            threshold=self.silence_threshold,
            duration=self.silence_duration,
            sample_rate=RATE,
            chunk_size=CHUNK
        )
        # ë‚´ë¶€ ìƒíƒœ
        self.audio_frames = []
        self.buffer_lock = threading.Lock()
        self.voice_detected = False
        self.chunk_duration = CHUNK / RATE
        self.silence_chunks = int(self.silence_duration / self.chunk_duration)

        # asyncio ì´ë²¤íŠ¸ ë£¨í”„
        self.loop = asyncio.new_event_loop()
        self.queue = asyncio.Queue()
        self.stop_event = asyncio.Event()

    def _calibrate_ambient(self):
        self.logger.info("ğŸŒ™ í™˜ê²½ ì†ŒìŒ ìº˜ë¦¬ë¸Œë ˆì´ì…˜: 2ì´ˆê°„ ì¸¡ì • ì¤‘...")
        for _ in range(int((RATE/CHUNK)*2)):
            data, _ = self.streamer.read_chunk()
            rms, _ = self.vad.get_audio_features(data)
            self.vad.update_background(rms)
        self.logger.info(f"ğŸŒ™ ì´ˆê¸° ë™ì  ì„ê³„ì¹˜: {self.vad.dynamic_threshold:.1f}")

    def set_gui_signals(self, signals):
        self.signals = signals

    def save_config(self):
        self.config["silence_threshold"] = self.silence_threshold
        self.config["silence_duration"] = self.silence_duration
        self.config["translation_mode"] = self.translation_mode
        self.config.save()
        # VAD íŒŒë¼ë¯¸í„° ì¦‰ì‹œ ë°˜ì˜
        self.vad.threshold = self.silence_threshold
        self.vad.silence_chunks = int(self.silence_duration / self.vad.chunk_duration)

    def get_audio_level(self, audio_data):
        return get_audio_level(audio_data)

    def start(self):
        self.streamer.open_stream()
        self.logger.info("âœ… ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘")
        # 1) ìŠ¤íŠ¸ë¦¼ ì—´ê¸°
        self.streamer.open_stream()
        self.logger.info("âœ… ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘")
        # 2) í™˜ê²½ ì†ŒìŒ ìº˜ë¦¬ë¸Œë ˆì´ì…˜
        self._calibrate_ambient()
        # 3) ìº¡ì²˜/ì²˜ë¦¬ ë£¨í”„ ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œë¡œ ì‹œì‘
        self.thread = threading.Thread(target=self._run_loop, daemon=True)
        self.thread.start()

    def _run_loop(self):
        asyncio.set_event_loop(self.loop)
        self.loop.create_task(self._capture_loop())
        self.loop.create_task(self._process_loop())
        self.loop.run_forever()

    async def _capture_loop(self):
        recording = False
        frames = []
        silence_count = 0

        while not self.stop_event.is_set():
            data, level = await self.loop.run_in_executor(None, self.streamer.read_chunk)
            # ì˜¤ë””ì˜¤ ë ˆë²¨ GUIì— ì „ë‹¬
            self.signals.audio_level_update.emit(level)

            # VAD
            rms, flux = self.vad.get_audio_features(data)
            self.vad.update_background(rms)
            th = self.vad.dynamic_threshold
            speech = (rms > th) or (flux > th * 0.5)

            if speech:
                if not recording:
                    recording = True
                    frames = []
                    silence_count = 0
                    self.signals.status_update.emit("â–¶ï¸ ë°œí™” ì‹œì‘: ë…¹ìŒ ì¤‘")
                frames.append(data)
                self.voice_detected = True
            else:
                if recording:
                    silence_count = 1
                    frames.append(data)
                    if silence_count >= self.vad.silence_chunks:
                        self.signals.status_update.emit("â¹ï¸ ë°œí™” ì¢…ë£Œ: ì²˜ë¦¬ íì— ì¶”ê°€")
                        await self.queue.put(frames.copy())
                        recording = False
                        frames = []
                        silence_count = 0
                        self.voice_detected = False

            self.signals.voice_detected.emit(self.voice_detected)
            await asyncio.sleep(self.update_interval)

    async def _process_loop(self):
        min_frames = int((RATE * 0.5) / CHUNK)

        while not self.stop_event.is_set():
            frames = await self.queue.get()
            if len(frames) < min_frames:
                continue

            # WAVë¡œ ì €ì¥
            path = await self.loop.run_in_executor(None, partial(save_wav, frames, CHANNELS, RATE))
            # ì „ì‚¬
            try:
                text = await self.loop.run_in_executor(None, partial(self.whisper.transcribe, path))
            except Exception as e:
                self.logger.error(f"Transcription error: {e}")
                continue

            if text:
                timestamp = datetime.now().strftime("%H:%M:%S")
                self.signals.status_update.emit(f"ğŸ”¤ ì¸ì‹ëœ í…ìŠ¤íŠ¸: {text}")
                # ë²ˆì—­
                try:
                    translation = await self.loop.run_in_executor(None, partial(self.gpt.translate, text))
                except Exception as e:
                    self.logger.error(f"Translation error: {e}")
                    continue

                if translation:
                    self.signals.status_update.emit("ğŸ“ ë²ˆì—­ ê²°ê³¼ ìˆ˜ì‹ ")
                    self.signals.translation_update.emit(timestamp, translation, text)

            await asyncio.sleep(0)

    def stop(self):
        self.stop_event.set()
        self.streamer.close()
        self.loop.call_soon_threadsafe(self.loop.stop)
        if hasattr(self, "thread"):
            self.thread.join()
        self.logger.info("ğŸ›‘ Translator ì¤‘ì§€ ì™„ë£Œ")
